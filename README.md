# Crawl Data from SCI-HUB

## Descriptions

This Jupyter Notebook is used to crawl data from sci-hub.

## How it works

The script is wrote in Python. 
It uses selenium to manipulate a web-driver, which hosts and controls a chrome web browser. 
To run this stuff:
- you need to install Python 3.6+ (installing with [Anaconda](https://www.anaconda.com/distribution/) is recommended!)
- you need to install jupyter (included in anaconda)
- you need to install chrome
- you need to install [chrome webdriver](https://chromedriver.chromium.org/downloads) (w.r.t. the corresponding chrome version)
- you need to install [selenium](https://selenium-python.readthedocs.io/)
- run `jupyter notebook`, open `downloader` and then start crawling (specific guidance is included in the notebook)
